{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4. Training and Test Data Set Split.ipynb","provenance":[{"file_id":"1lrY6Xof5OO95i26qHzizhbOaPFaIWBTs","timestamp":1627303340160},{"file_id":"1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX","timestamp":1624900641646},{"file_id":"1dcucJvUOx6kdopjhVIwIdpby6VXhnvns","timestamp":1575478354980},{"file_id":"1ywsvwO6thOVOrfagjjfuxEf6xVRxbUNO","timestamp":1575307876986},{"file_id":"1f_snPs--PVYgZJwT3GwjxqVALFJ0T2-y","timestamp":1556493831452}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RX_ZDhicpHkV"},"source":["# 1. Setup"]},{"cell_type":"markdown","metadata":{"id":"nSU7yERLP_66"},"source":["## 1.1.Importing and installing the necessary libraries\n"]},{"cell_type":"code","metadata":{"id":"EUGodtjkogKz"},"source":["# Importing necessary librairies\n","from google.colab import drive\n","import numpy as np\n","import pandas as pd\n","import pickle \n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GPmomD1MQUie"},"source":["## 1.2. Importing personal drive to file in order to later load the data and the saved fine tuned model\n"]},{"cell_type":"code","metadata":{"id":"Sxm1uIhjQUE9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627637814774,"user_tz":-120,"elapsed":14289,"user":{"displayName":"SummaDev AFD","photoUrl":"","userId":"09833408258532841698"}},"outputId":"fd72a4f6-1b6e-41a6-e474-89a617ce6de8"},"source":["# Mount Google Drive to this Notebook instance.\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oQUy9Tat2EF_"},"source":["## 2. Load and Format data"]},{"cell_type":"markdown","metadata":{"id":"di2eTGRcqpyC"},"source":["## 2.1. Loading the clean data\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"VbpRe9QcT3Vx"},"source":["# We load the cleaned data from a pickle format\n","file ='/content/drive/MyDrive/Data/SummaDevDocs_preprocessed.pickle'\n","df = pd.read_pickle(file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5dar_370bkl","colab":{"base_uri":"https://localhost:8080/","height":581},"executionInfo":{"status":"ok","timestamp":1627637819851,"user_tz":-120,"elapsed":330,"user":{"displayName":"SummaDev AFD","photoUrl":"","userId":"09833408258532841698"}},"outputId":"b373ce77-3366-4f2a-cd8c-b874bd5f95ec"},"source":["# Looking at the data\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document_text</th>\n","      <th>summary_text</th>\n","      <th>text_clean</th>\n","      <th>text_embedding</th>\n","      <th>summary_clean</th>\n","      <th>summary_embedding</th>\n","      <th>labels</th>\n","      <th>doc_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The training improved women’s knowledge on the...</td>\n","      <td>The training improved women’s knowledge on the...</td>\n","      <td>[The training improved women’s knowledge on th...</td>\n","      <td>[[0.76747984, -0.18944956, 0.51285803, -0.0211...</td>\n","      <td>[The training improved women’s knowledge on th...</td>\n","      <td>[[0.76747984, -0.18944956, 0.51285803, -0.0211...</td>\n","      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Illegal oil refining in the Niger Delta is inc...</td>\n","      <td>CEHRD in an effort to create awareness on the ...</td>\n","      <td>[Illegal oil refining in the Niger Delta is in...</td>\n","      <td>[[-0.34167996, -0.6055787, -0.20679495, -1.148...</td>\n","      <td>[CEHRD in an effort to create awareness on the...</td>\n","      <td>[[-0.436482, -0.07113252, -0.18081762, -0.4864...</td>\n","      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CEHRD successfully set-up 4 formal and 4 infor...</td>\n","      <td>CEHRD set-up the environmental clubs with the ...</td>\n","      <td>[CEHRD successfully set-up 4 formal and 4 info...</td>\n","      <td>[[-0.4896432, -1.2085572, 1.0374498, 0.0213696...</td>\n","      <td>[CEHRD set-up the environmental clubs with the...</td>\n","      <td>[[-0.15335679, -0.2943071, 0.58692193, -1.1263...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>PROJECT NAME : Delivering Accelerated Family P...</td>\n","      <td>Delivering Accelerated Family Planning in Paki...</td>\n","      <td>[PROJECT NAME :, Delivering Accelerated Family...</td>\n","      <td>[[-0.23698464, 0.15983887, -0.07119872, -1.200...</td>\n","      <td>[Delivering Accelerated Family Planning in Pak...</td>\n","      <td>[[-0.50266284, -1.2923898, 0.42068344, -1.2567...</td>\n","      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Road traffic injuries are world's eighth leadi...</td>\n","      <td>The Cardiff Trauma Pack Research and Develop...</td>\n","      <td>[Road traffic injuries are world's eighth lead...</td>\n","      <td>[[-0.466682, -1.1917696, 0.99453795, -0.957597...</td>\n","      <td>[  The Cardiff Trauma Pack Research and Develo...</td>\n","      <td>[[-0.4679709, -0.43502185, 0.83883774, -1.4754...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2980</th>\n","      <td>Metta has been responding to the humanitarian ...</td>\n","      <td>ProjectGoal: To improve the condition of 2,854...</td>\n","      <td>[Metta has been responding to the humanitarian...</td>\n","      <td>[[-0.6875753, -1.0828757, 0.32236812, -1.33987...</td>\n","      <td>[ProjectGoal:, To improve the condition of 2,8...</td>\n","      <td>[[-0.5820974, 0.02791187, 0.2928526, -1.098855...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...</td>\n","      <td>[2980, 2980, 2980, 2980, 2980, 2980, 2980, 298...</td>\n","    </tr>\n","    <tr>\n","      <th>2981</th>\n","      <td>Destined Women is local not for profit\\, non-r...</td>\n","      <td>GOAL: Contribute towards changing the socioeco...</td>\n","      <td>[Destined Women is local not for profit\\,, non...</td>\n","      <td>[[-0.91105515, -0.780988, -0.013189635, -0.504...</td>\n","      <td>[GOAL: Contribute towards changing the socioec...</td>\n","      <td>[[0.06080835, -0.2223898, 0.48705336, -1.54801...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>[2981, 2981, 2981, 2981, 2981, 2981, 2981, 298...</td>\n","    </tr>\n","    <tr>\n","      <th>2982</th>\n","      <td>The project will empower secondary school stud...</td>\n","      <td>The project will empower secondary school stud...</td>\n","      <td>[The project will empower secondary school stu...</td>\n","      <td>[[0.2446245, -0.58844894, 1.0700818, -0.348946...</td>\n","      <td>[The project will empower secondary school stu...</td>\n","      <td>[[0.31522802, -0.6220454, 1.084553, -0.3928656...</td>\n","      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","      <td>[2982, 2982, 2982, 2982, 2982, 2982, 2982]</td>\n","    </tr>\n","    <tr>\n","      <th>2983</th>\n","      <td>The project has been specifically designed to ...</td>\n","      <td>The project has been specifically designed to ...</td>\n","      <td>[The project has been specifically designed to...</td>\n","      <td>[[0.22308932, -0.042834148, 0.5815844, -0.4814...</td>\n","      <td>[The project has been specifically designed to...</td>\n","      <td>[[0.24488513, -0.04303686, 0.55787843, -0.5100...</td>\n","      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","      <td>[2983, 2983, 2983, 2983, 2983, 2983]</td>\n","    </tr>\n","    <tr>\n","      <th>2984</th>\n","      <td>the project \"\"Collective Voice and Action for ...</td>\n","      <td>The project aims that \"\"Migrant workers and in...</td>\n","      <td>[the project \"\"Collective Voice and Action for...</td>\n","      <td>[[-0.009599792, 0.0015055225, 0.8592731, -1.05...</td>\n","      <td>[The project aims that \"\"Migrant workers and i...</td>\n","      <td>[[-0.09781192, 0.027989447, 0.81042004, -1.270...</td>\n","      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>[2984, 2984, 2984, 2984, 2984, 2984, 2984, 298...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2985 rows × 8 columns</p>\n","</div>"],"text/plain":["                                          document_text  ...                                          doc_label\n","0     The training improved women’s knowledge on the...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","1     Illegal oil refining in the Niger Delta is inc...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n","2     CEHRD successfully set-up 4 formal and 4 infor...  ...  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...\n","3     PROJECT NAME : Delivering Accelerated Family P...  ...  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n","4     Road traffic injuries are world's eighth leadi...  ...  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...\n","...                                                 ...  ...                                                ...\n","2980  Metta has been responding to the humanitarian ...  ...  [2980, 2980, 2980, 2980, 2980, 2980, 2980, 298...\n","2981  Destined Women is local not for profit\\, non-r...  ...  [2981, 2981, 2981, 2981, 2981, 2981, 2981, 298...\n","2982  The project will empower secondary school stud...  ...         [2982, 2982, 2982, 2982, 2982, 2982, 2982]\n","2983  The project has been specifically designed to ...  ...               [2983, 2983, 2983, 2983, 2983, 2983]\n","2984  the project \"\"Collective Voice and Action for ...  ...  [2984, 2984, 2984, 2984, 2984, 2984, 2984, 298...\n","\n","[2985 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"jch-3amFq6LU"},"source":["## 2.2. Creating the train and test sets in the right format"]},{"cell_type":"markdown","metadata":{"id":"ut_2sU13rCdH"},"source":["### 2.2.1. Creating the train set, with each row being a sentence \n","\n"]},{"cell_type":"code","metadata":{"id":"Q9iUASs9VJO8","colab":{"base_uri":"https://localhost:8080/","height":202},"executionInfo":{"status":"ok","timestamp":1627637831123,"user_tz":-120,"elapsed":650,"user":{"displayName":"SummaDev AFD","photoUrl":"","userId":"09833408258532841698"}},"outputId":"4c3811d4-8e1e-4ca9-801a-d6254a866418"},"source":["# Splitting the dataframe into a train and a test set, keeping 20% for the test set. \n","train_dataset, test_dataset = train_test_split(df, test_size=0.2)\n","\n","# We wish to split each sentence individually for the purpose of classification. \n","#for this reason, we create three empty lists to later feed them with the individual sentences, associated with their label and document label \n","sentences, labels, document_labels = [], [], []\n","\n","# We do the below to feed the empty lists\n","#looping through the embeddings, the document labels, the text and the target labels\n","for doc_x, doc_y, doc_label in zip(train_dataset['text_clean'], \n","                                   train_dataset['labels'], \n","                                   train_dataset['doc_label']):\n","                                          \n","#looping through each item within the text, the target labels, the document labels\n","    for i, (sent, target, label) in enumerate(zip(doc_x, doc_y, doc_label)):\n","        \n","        #appending each item to the empty lists previously created \n","        sentences.append(sent) #this will be used to train the data points \n","        labels.append(target) #this will be used to train the data points\n","        document_labels.append(label) #this will be used to retrieve the intial document the sentence belongs to \n","\n","# We then create a dataframe out of the created lists \n","train_dataset = pd.DataFrame({'sentence': sentences,\n","                             'label' :  labels,\n","                             'document_label': document_labels\n","                             })\n","\n","# For precision, we convert the current float labels to integers \n","#creation of an empty list\n","new_label = []\n","\n","#looping in the label column, converting each label to an integer and appending to the new_label list\n","for i in train_dataset['label']:\n","  i = int(i)\n","  new_label.append(i)  \n","\n","#updating the label column with the new_label list\n","train_dataset['label'] = new_label\n","\n","# Exporting to csv file\n","train_dataset.to_csv('train_dataset.csv', index=False)\n","\n","# Viewing the pre-formatted train_dataset\n","train_dataset.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","      <th>document_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The development objective of Trade Logistics P...</td>\n","      <td>1</td>\n","      <td>1668</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>This project has three components.</td>\n","      <td>0</td>\n","      <td>1668</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1)</td>\n","      <td>0</td>\n","      <td>1668</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The first component\\, : Improvement of infrast...</td>\n","      <td>0</td>\n","      <td>1668</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2)</td>\n","      <td>0</td>\n","      <td>1668</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  label  document_label\n","0  The development objective of Trade Logistics P...      1            1668\n","1                 This project has three components.      0            1668\n","2                                                 1)      0            1668\n","3  The first component\\, : Improvement of infrast...      0            1668\n","4                                                 2)      0            1668"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"On3h4_fnrWD-"},"source":["### 2.2.2. Creating the test set, with each row being a sentence\n"]},{"cell_type":"code","metadata":{"id":"2sTND_XzKgbD","colab":{"base_uri":"https://localhost:8080/","height":202},"executionInfo":{"status":"ok","timestamp":1627637832231,"user_tz":-120,"elapsed":5,"user":{"displayName":"SummaDev AFD","photoUrl":"","userId":"09833408258532841698"}},"outputId":"c1ea6a34-c6f2-4669-8a12-0a4d3d9eaf0a"},"source":["# We repeat the same process for the test_dataset\n","\n","# Creating empty lists \n","sentences, labels, document_labels = [], [], [] \n","\n","#looping through the embeddings, the document labels, the text and the target labels\n","for doc_x, doc_y, doc_label in zip(test_dataset['text_clean'], \n","                                   test_dataset['labels'], \n","                                   test_dataset['doc_label']):\n","                                          \n","    #looping through each item within the text, the target labels, the document labels\n","    for i, (sent, target, label) in enumerate(zip(doc_x, doc_y, doc_label )):\n","        \n","        #appending each item to the empty lists previously created \n","        sentences.append(sent) #this will be used to train the data points \n","        labels.append(target) #this will be used to train the data points\n","        document_labels.append(label) #this will be used to retrieve the intial document the sentence belongs to \n","\n","# Creating a new test_dataset dataframe with appropriate lists \n","test_dataset = pd.DataFrame({'sentence': sentences,\n","                             'label' :  labels,\n","                             'document_label': document_labels,\n","                             })\n","\n","# Converting float labels to integers \n","new_label = []\n","\n","for i in test_dataset['label']:\n","  i = int(i)\n","  new_label.append(i)   \n","\n","#updating the label column with the new_label list\n","test_dataset['label'] = new_label\n","\n","# Exporting to csv file\n","test_dataset.to_csv('test_dataset.csv', index=False)\n","\n","# Viewing the pre-formatted train_dataset\n","test_dataset.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","      <th>document_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The main purpose of this project is to support...</td>\n","      <td>1</td>\n","      <td>1272</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>To do\\nso\\, the Rio+Social Programme focuses o...</td>\n","      <td>0</td>\n","      <td>1272</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The project outputs and activities are\\norgani...</td>\n","      <td>0</td>\n","      <td>1272</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>(EAs):EA1:</td>\n","      <td>0</td>\n","      <td>1272</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Urban and\\nsocial information on pacified comm...</td>\n","      <td>0</td>\n","      <td>1272</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  label  document_label\n","0  The main purpose of this project is to support...      1            1272\n","1  To do\\nso\\, the Rio+Social Programme focuses o...      0            1272\n","2  The project outputs and activities are\\norgani...      0            1272\n","3                                         (EAs):EA1:      0            1272\n","4  Urban and\\nsocial information on pacified comm...      0            1272"]},"metadata":{"tags":[]},"execution_count":6}]}]}